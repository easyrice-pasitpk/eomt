MASTER_PORT=10547
WORLD_SIZE=4
MASTER_ADDR=lanta-g-012
[rank: 2] Seed set to 0
[rank: 3] Seed set to 0
[rank: 1] Seed set to 0
[rank: 0] Seed set to 0
Using 16bit Automatic Mixed Precision (AMP)
Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id dhboz88b.
wandb: Tracking run with wandb version 0.19.10
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loading `train_dataloader` to estimate number of stepping batches.
/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (41) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.

   | Name                     | Type                        | Params | Mode 
----------------------------------------------------------------------------------
0  | network                  | EoMT                        | 23.3 M | train
1  | network.encoder          | ViT                         | 21.6 M | train
2  | network.encoder.backbone | DINOv3ViTModel              | 21.6 M | eval 
3  | network.q                | Embedding                   | 76.8 K | train
4  | network.class_head       | Linear                      | 770    | train
5  | network.mask_head        | Sequential                  | 443 K  | train
6  | network.mask_head.0      | Linear                      | 147 K  | train
7  | network.mask_head.1      | GELU                        | 0      | train
8  | network.mask_head.2      | Linear                      | 147 K  | train
9  | network.mask_head.3      | GELU                        | 0      | train
10 | network.mask_head.4      | Linear                      | 147 K  | train
11 | network.upscale          | Sequential                  | 1.2 M  | train
12 | network.upscale.0        | ScaleBlock                  | 594 K  | train
13 | network.upscale.1        | ScaleBlock                  | 594 K  | train
14 | criterion                | MaskClassificationLoss      | 0      | train
15 | criterion.matcher        | Mask2FormerHungarianMatcher | 0      | train
16 | metrics                  | ModuleList                  | 0      | train
17 | metrics.0                | MeanAveragePrecision        | 0      | train
18 | metrics.1                | MeanAveragePrecision        | 0      | train
19 | metrics.2                | MeanAveragePrecision        | 0      | train
20 | metrics.3                | MeanAveragePrecision        | 0      | train
21 | metrics.4                | MeanAveragePrecision        | 0      | train
----------------------------------------------------------------------------------
23.3 M    Trainable params
0         Non-trainable params
23.3 M    Total params
93.224    Total estimated model params size (MB)
29        Modules in train mode
186       Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
[rank3]: Traceback (most recent call last):
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 188, in <module>
[rank3]:     cli_main()
[rank3]:     ~~~~~~~~^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 166, in cli_main
[rank3]:     LightningCLI(
[rank3]:     ~~~~~~~~~~~~^
[rank3]:         LightningModule,
[rank3]:         ^^^^^^^^^^^^^^^^
[rank3]:     ...<15 lines>...
[rank3]:         },
[rank3]:         ^^
[rank3]:     )
[rank3]:     ^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 116, in __init__
[rank3]:     super().__init__(*args, **kwargs)
[rank3]:     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/cli.py", line 398, in __init__
[rank3]:     self._run_subcommand(self.subcommand)
[rank3]:     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/cli.py", line 708, in _run_subcommand
[rank3]:     fn(**fn_kwargs)
[rank3]:     ~~^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 162, in fit
[rank3]:     self.trainer.fit(model, **kwargs)
[rank3]:     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
[rank3]:         self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
[rank3]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:     )
[rank3]:     ^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank3]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank3]:            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:     ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
[rank3]:     results = self._run_stage()
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:     ~~~~~~~~~~~~~~~~~^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank3]:     self.advance()
[rank3]:     ~~~~~~~~~~~~^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:     ~~~~~~~~~~~~^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 320, in advance
[rank3]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 192, in run
[rank3]:     self._optimizer_step(batch_idx, closure)
[rank3]:     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 270, in _optimizer_step
[rank3]:     call._call_lightning_module_hook(
[rank3]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
[rank3]:         trainer,
[rank3]:         ^^^^^^^^
[rank3]:     ...<4 lines>...
[rank3]:         train_step_and_backward_closure,
[rank3]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:     )
[rank3]:     ^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 176, in _call_lightning_module_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/core/module.py", line 1302, in optimizer_step
[rank3]:     optimizer.step(closure=optimizer_closure)
[rank3]:     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/core/optimizer.py", line 154, in step
[rank3]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
[rank3]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
[rank3]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank3]:            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/plugins/precision/amp.py", line 79, in optimizer_step
[rank3]:     closure_result = closure()
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 146, in __call__
[rank3]:     self._result = self.closure(*args, **kwargs)
[rank3]:                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 131, in closure
[rank3]:     step_output = self._step_fn()
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 319, in _training_step
[rank3]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
[rank3]:     output = fn(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 390, in training_step
[rank3]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank3]:            ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
[rank3]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/parallel/distributed.py", line 1637, in forward
[rank3]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank3]:          ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/parallel/distributed.py", line 1464, in _run_ddp_forward
[rank3]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank3]:            ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
[rank3]:     out = method(*_args, **_kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/training/lightning_module.py", line 169, in training_step
[rank3]:     mask_logits_per_block, class_logits_per_block = self(imgs)
[rank3]:                                                     ~~~~^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/training/lightning_module.py", line 164, in forward
[rank3]:     return self.network(x)
[rank3]:            ~~~~~~~~~~~~^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/eomt.py", line 197, in forward
[rank3]:     mask_logits, class_logits = self._predict(self.encoder.backbone.norm(x))
[rank3]:                                 ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/eomt.py", line 66, in _predict
[rank3]:     "bqc, bchw -> bqhw", self.mask_head(q), self.upscale(x)
[rank3]:                                             ~~~~~~~~~~~~^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py", line 240, in forward
[rank3]:     input = module(input)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/scale_block.py", line 36, in forward
[rank3]:     x = self.norm(x)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/timm/layers/norm.py", line 84, in forward
[rank3]:     x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)
[rank3]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/functional.py", line 2910, in layer_norm
[rank3]:     return torch.layer_norm(
[rank3]:            ~~~~~~~~~~~~~~~~^
[rank3]:         input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled
[rank3]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank3]:     )
[rank3]:     ^
[rank3]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.17 GiB. GPU 3 has a total capacity of 39.50 GiB of which 562.12 MiB is free. Including non-PyTorch memory, this process has 38.93 GiB memory in use. Of the allocated memory 36.41 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank2]: Traceback (most recent call last):
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 188, in <module>
[rank2]:     cli_main()
[rank2]:     ~~~~~~~~^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 166, in cli_main
[rank2]:     LightningCLI(
[rank2]:     ~~~~~~~~~~~~^
[rank2]:         LightningModule,
[rank2]:         ^^^^^^^^^^^^^^^^
[rank2]:     ...<15 lines>...
[rank2]:         },
[rank2]:         ^^
[rank2]:     )
[rank2]:     ^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 116, in __init__
[rank2]:     super().__init__(*args, **kwargs)
[rank2]:     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/cli.py", line 398, in __init__
[rank2]:     self._run_subcommand(self.subcommand)
[rank2]:     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/cli.py", line 708, in _run_subcommand
[rank2]:     fn(**fn_kwargs)
[rank2]:     ~~^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 162, in fit
[rank2]:     self.trainer.fit(model, **kwargs)
[rank2]:     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
[rank2]:         self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
[rank2]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:     )
[rank2]:     ^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank2]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank2]:            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:     ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
[rank2]:     results = self._run_stage()
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
[rank2]:     self.fit_loop.run()
[rank2]:     ~~~~~~~~~~~~~~~~~^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank2]:     self.advance()
[rank2]:     ~~~~~~~~~~~~^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:     ~~~~~~~~~~~~^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 320, in advance
[rank2]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 192, in run
[rank2]:     self._optimizer_step(batch_idx, closure)
[rank2]:     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 270, in _optimizer_step
[rank2]:     call._call_lightning_module_hook(
[rank2]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
[rank2]:         trainer,
[rank2]:         ^^^^^^^^
[rank2]:     ...<4 lines>...
[rank2]:         train_step_and_backward_closure,
[rank2]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:     )
[rank2]:     ^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 176, in _call_lightning_module_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/core/module.py", line 1302, in optimizer_step
[rank2]:     optimizer.step(closure=optimizer_closure)
[rank2]:     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/core/optimizer.py", line 154, in step
[rank2]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
[rank2]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
[rank2]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank2]:            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/plugins/precision/amp.py", line 79, in optimizer_step
[rank2]:     closure_result = closure()
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 146, in __call__
[rank2]:     self._result = self.closure(*args, **kwargs)
[rank2]:                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 131, in closure
[rank2]:     step_output = self._step_fn()
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 319, in _training_step
[rank2]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
[rank2]:     output = fn(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 390, in training_step
[rank2]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank2]:            ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
[rank2]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/parallel/distributed.py", line 1637, in forward
[rank2]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank2]:          ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/parallel/distributed.py", line 1464, in _run_ddp_forward
[rank2]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank2]:            ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
[rank2]:     out = method(*_args, **_kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/training/lightning_module.py", line 169, in training_step
[rank2]:     mask_logits_per_block, class_logits_per_block = self(imgs)
[rank2]:                                                     ~~~~^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/training/lightning_module.py", line 164, in forward
[rank2]:     return self.network(x)
[rank2]:            ~~~~~~~~~~~~^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/eomt.py", line 197, in forward
[rank2]:     mask_logits, class_logits = self._predict(self.encoder.backbone.norm(x))
[rank2]:                                 ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/eomt.py", line 66, in _predict
[rank2]:     "bqc, bchw -> bqhw", self.mask_head(q), self.upscale(x)
[rank2]:                                             ~~~~~~~~~~~~^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py", line 240, in forward
[rank2]:     input = module(input)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/scale_block.py", line 36, in forward
[rank2]:     x = self.norm(x)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/timm/layers/norm.py", line 84, in forward
[rank2]:     x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)
[rank2]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/functional.py", line 2910, in layer_norm
[rank2]:     return torch.layer_norm(
[rank2]:            ~~~~~~~~~~~~~~~~^
[rank2]:         input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled
[rank2]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]:     )
[rank2]:     ^
[rank2]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.17 GiB. GPU 2 has a total capacity of 39.50 GiB of which 632.12 MiB is free. Including non-PyTorch memory, this process has 38.86 GiB memory in use. Of the allocated memory 36.33 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 188, in <module>
[rank1]:     cli_main()
[rank1]:     ~~~~~~~~^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 166, in cli_main
[rank1]:     LightningCLI(
[rank1]:     ~~~~~~~~~~~~^
[rank1]:         LightningModule,
[rank1]:         ^^^^^^^^^^^^^^^^
[rank1]:     ...<15 lines>...
[rank1]:         },
[rank1]:         ^^
[rank1]:     )
[rank1]:     ^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 116, in __init__
[rank1]:     super().__init__(*args, **kwargs)
[rank1]:     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/cli.py", line 398, in __init__
[rank1]:     self._run_subcommand(self.subcommand)
[rank1]:     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/cli.py", line 708, in _run_subcommand
[rank1]:     fn(**fn_kwargs)
[rank1]:     ~~^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 162, in fit
[rank1]:     self.trainer.fit(model, **kwargs)
[rank1]:     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
[rank1]:         self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
[rank1]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:     )
[rank1]:     ^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank1]:            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:     ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
[rank1]:     results = self._run_stage()
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
[rank1]:     self.fit_loop.run()
[rank1]:     ~~~~~~~~~~~~~~~~~^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank1]:     self.advance()
[rank1]:     ~~~~~~~~~~~~^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank1]:     self.advance(data_fetcher)
[rank1]:     ~~~~~~~~~~~~^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 320, in advance
[rank1]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 192, in run
[rank1]:     self._optimizer_step(batch_idx, closure)
[rank1]:     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 270, in _optimizer_step
[rank1]:     call._call_lightning_module_hook(
[rank1]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
[rank1]:         trainer,
[rank1]:         ^^^^^^^^
[rank1]:     ...<4 lines>...
[rank1]:         train_step_and_backward_closure,
[rank1]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:     )
[rank1]:     ^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 176, in _call_lightning_module_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/core/module.py", line 1302, in optimizer_step
[rank1]:     optimizer.step(closure=optimizer_closure)
[rank1]:     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/core/optimizer.py", line 154, in step
[rank1]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
[rank1]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
[rank1]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank1]:            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/plugins/precision/amp.py", line 79, in optimizer_step
[rank1]:     closure_result = closure()
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 146, in __call__
[rank1]:     self._result = self.closure(*args, **kwargs)
[rank1]:                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 131, in closure
[rank1]:     step_output = self._step_fn()
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 319, in _training_step
[rank1]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
[rank1]:     output = fn(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 390, in training_step
[rank1]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank1]:            ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
[rank1]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/parallel/distributed.py", line 1637, in forward
[rank1]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank1]:          ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/parallel/distributed.py", line 1464, in _run_ddp_forward
[rank1]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank1]:            ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
[rank1]:     out = method(*_args, **_kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/training/lightning_module.py", line 169, in training_step
[rank1]:     mask_logits_per_block, class_logits_per_block = self(imgs)
[rank1]:                                                     ~~~~^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/training/lightning_module.py", line 164, in forward
[rank1]:     return self.network(x)
[rank1]:            ~~~~~~~~~~~~^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/eomt.py", line 197, in forward
[rank1]:     mask_logits, class_logits = self._predict(self.encoder.backbone.norm(x))
[rank1]:                                 ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/eomt.py", line 66, in _predict
[rank1]:     "bqc, bchw -> bqhw", self.mask_head(q), self.upscale(x)
[rank1]:                                             ~~~~~~~~~~~~^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py", line 240, in forward
[rank1]:     input = module(input)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/scale_block.py", line 36, in forward
[rank1]:     x = self.norm(x)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/timm/layers/norm.py", line 84, in forward
[rank1]:     x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)
[rank1]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/functional.py", line 2910, in layer_norm
[rank1]:     return torch.layer_norm(
[rank1]:            ~~~~~~~~~~~~~~~~^
[rank1]:         input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled
[rank1]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:     )
[rank1]:     ^
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.17 GiB. GPU 1 has a total capacity of 39.50 GiB of which 502.12 MiB is free. Including non-PyTorch memory, this process has 38.99 GiB memory in use. Of the allocated memory 36.41 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 188, in <module>
[rank0]:     cli_main()
[rank0]:     ~~~~~~~~^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 166, in cli_main
[rank0]:     LightningCLI(
[rank0]:     ~~~~~~~~~~~~^
[rank0]:         LightningModule,
[rank0]:         ^^^^^^^^^^^^^^^^
[rank0]:     ...<15 lines>...
[rank0]:         },
[rank0]:         ^^
[rank0]:     )
[rank0]:     ^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 116, in __init__
[rank0]:     super().__init__(*args, **kwargs)
[rank0]:     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/cli.py", line 398, in __init__
[rank0]:     self._run_subcommand(self.subcommand)
[rank0]:     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/cli.py", line 708, in _run_subcommand
[rank0]:     fn(**fn_kwargs)
[rank0]:     ~~^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/main.py", line 162, in fit
[rank0]:     self.trainer.fit(model, **kwargs)
[rank0]:     ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 561, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
[rank0]:         self, self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:     )
[rank0]:     ^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 599, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:     ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 1012, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/trainer.py", line 1056, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:     ~~~~~~~~~~~~~~~~~^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank0]:     self.advance()
[rank0]:     ~~~~~~~~~~~~^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:     ~~~~~~~~~~~~^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 320, in advance
[rank0]:     batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 192, in run
[rank0]:     self._optimizer_step(batch_idx, closure)
[rank0]:     ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 270, in _optimizer_step
[rank0]:     call._call_lightning_module_hook(
[rank0]:     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
[rank0]:         trainer,
[rank0]:         ^^^^^^^^
[rank0]:     ...<4 lines>...
[rank0]:         train_step_and_backward_closure,
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:     )
[rank0]:     ^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 176, in _call_lightning_module_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/core/module.py", line 1302, in optimizer_step
[rank0]:     optimizer.step(closure=optimizer_closure)
[rank0]:     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/core/optimizer.py", line 154, in step
[rank0]:     step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/ddp.py", line 270, in optimizer_step
[rank0]:     optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 239, in optimizer_step
[rank0]:     return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
[rank0]:            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/plugins/precision/amp.py", line 79, in optimizer_step
[rank0]:     closure_result = closure()
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 146, in __call__
[rank0]:     self._result = self.closure(*args, **kwargs)
[rank0]:                    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 131, in closure
[rank0]:     step_output = self._step_fn()
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/loops/optimization/automatic.py", line 319, in _training_step
[rank0]:     training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/trainer/call.py", line 328, in _call_strategy_hook
[rank0]:     output = fn(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 390, in training_step
[rank0]:     return self._forward_redirection(self.model, self.lightning_module, "training_step", *args, **kwargs)
[rank0]:            ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 641, in __call__
[rank0]:     wrapper_output = wrapper_module(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/parallel/distributed.py", line 1637, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:          ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/parallel/distributed.py", line 1464, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:            ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/lightning/pytorch/strategies/strategy.py", line 634, in wrapped_forward
[rank0]:     out = method(*_args, **_kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/training/lightning_module.py", line 169, in training_step
[rank0]:     mask_logits_per_block, class_logits_per_block = self(imgs)
[rank0]:                                                     ~~~~^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/training/lightning_module.py", line 164, in forward
[rank0]:     return self.network(x)
[rank0]:            ~~~~~~~~~~~~^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/eomt.py", line 197, in forward
[rank0]:     mask_logits, class_logits = self._predict(self.encoder.backbone.norm(x))
[rank0]:                                 ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/eomt.py", line 66, in _predict
[rank0]:     "bqc, bchw -> bqhw", self.mask_head(q), self.upscale(x)
[rank0]:                                             ~~~~~~~~~~~~^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/container.py", line 240, in forward
[rank0]:     input = module(input)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/models/scale_block.py", line 36, in forward
[rank0]:     x = self.norm(x)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/timm/layers/norm.py", line 84, in forward
[rank0]:     x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)
[rank0]:   File "/lustrefs/disk/home/pjakkraw/workspace/eomt/.venv/lib/python3.13/site-packages/torch/nn/functional.py", line 2910, in layer_norm
[rank0]:     return torch.layer_norm(
[rank0]:            ~~~~~~~~~~~~~~~~^
[rank0]:         input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:     )
[rank0]:     ^
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.17 GiB. GPU 0 has a total capacity of 39.50 GiB of which 574.12 MiB is free. Including non-PyTorch memory, this process has 38.92 GiB memory in use. Of the allocated memory 36.38 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:26<00:26,  0.04it/s]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:42<00:00,  0.05it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/41 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/41 [00:00<?, ?it/s] [1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync ./wandb/offline-run-20251001_044640-dhboz88b[0m
srun: error: lanta-g-012: task 2: Exited with exit code 1
srun: Terminating StepId=3040547.0
slurmstepd: error: *** STEP 3040547.0 ON lanta-g-012 CANCELLED AT 2025-10-01T05:38:01 ***
srun: error: lanta-g-012: task 3: Exited with exit code 1
srun: error: lanta-g-012: task 0: Exited with exit code 1
srun: error: lanta-g-012: task 1: Exited with exit code 1
